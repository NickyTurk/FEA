import os
import sys
import torch
from predictionalgorithms.CNN_yieldpredictor.Predictor import utils, DataLoader
import pickle
import numpy as np
import matplotlib.pyplot as plt
from predictionalgorithms.CNN_yieldpredictor.Predictor.DataLoader import loadData
from scipy.interpolate import splrep, splev
from predictionalgorithms.CNN_yieldpredictor.PredictorStrategy.PredictorModel import PredictorModel

"""""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """
""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""
Static Functions
""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""
""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """"""


def clear_border(map_in, r_value):
    """Set the value of the pixels on the borders"""
    map_in[0:3, :] = r_value
    map_in[-3:, :] = r_value
    map_in[:, 0:3] = r_value
    map_in[:, -3:] = r_value

    return map_in


"""""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """
""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""
Main Class Definition
""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""
""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """""" """"""


class YieldMapPredictor:
    """Class used to predict an entire yield map using on a previously trained model."""

    def __init__(
        self,
        field: str,
        training_years: list,
        pred_year: int,
        data_mode="AggRADARPrec",
        cov=None,
        filename=None,
    ):
        """
        @param filename: Path containing the data (CSV)
        @param field: Name of the specific field that will be analyzed.
        @param training_years: Declare the years of data that will be used for training.
        @param pred_year: The year that will be used for prediction.
        @param data_mode: Determine the features that will be used. Options: 'All', 'AggRADAR', 'AllPrec'.
        @param cov:  Optional. Explicit list of covariates that will be used for training. Ex: ['N', 'NDVI', 'elev'].
        """
        # Set parameters
        self.filename = filename
        self.field = field
        self.training_years = training_years
        self.pred_year = pred_year
        self.data_mode = data_mode

        # Define variables
        self.windowSize = None
        self.outputSize = None
        self.modelType = None
        self.device = None
        self.model = None
        self.cellids = None
        self.coords = None
        self.simple_coords = []
        self.data = None
        self.nbands = None
        self.mask_field = None
        self.prev_n = None
        self.path_model = None
        self.maxs = None
        self.mins = None
        self.maxY = None
        self.minY = None
        self.patches = None
        self.centers = None

        # Initialize data loader object
        self.dataLoader = DataLoader.DataLoader(
            filename=filename,
            field=field,
            training_years=training_years,
            pred_year=pred_year,
            mode=data_mode,
            cov=cov,
        )

    def init_model(self, modelType: str):
        """Initialize  ML model."""
        self.modelType = modelType
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

        # Set input window size. If the model is a CNN, the input is 2D
        if modelType in ["Hyper3DNet", "Hyper3DNetQD", "Russello", "CNNLF"]:
            self.windowSize = 5
        else:
            self.windowSize = 1
            self.outputSize = 1
        # Set output window size. If the model is Hyper3DNet, the output is 2D
        if "Hyper3DNet" in modelType:
            self.outputSize = 5
        else:
            self.outputSize = 1

        return PredictorModel(
            self.modelType, self.device, self.nbands, self.windowSize, self.outputSize
        )

    def load_pred_data(self, objective, modifyNRate=None, clearBorder=True):
        """Load and prepare the data that will be used for prediction"""
        # Load the entire yield map and the features of the selected year
        self.data, self.cellids, self.coords, self.simple_coords = self.dataLoader.load_raster(
            objective=objective
        )
        self.nbands = self.data.shape[2]  # Stores the number of features in the dataset.
        self.prev_n = self.data[
            :, :, 0
        ].copy()  # Save for plotting later in case new prescription maps are used.

        # Modify N map using an uniform N rate
        if modifyNRate is not None:
            self.modifyPrescription(method="uniform", n_rate=modifyNRate)

        # Obtain a binary mask of the field (mask==1: field, mask==0: out of the field)
        self.mask_field = (self.data[:, :, 2] * 0).astype(
            np.uint8
        )  # The elevation raster is used as a reference.
        self.mask_field[
            np.where(self.data[:, :, 2] != 0)
        ] = 1  # There is field where the value is different than 0
        self.mask_field[
            np.where(self.data[:, :, 0] == -1)
        ] = 0  # Remove from analysis points with missing N values
        if clearBorder:
            self.mask_field = clear_border(self.mask_field, 0)

    def extract2DPatches(self):
        """Extract patches that will be analyzed by the CNN and their corresponding center positions"""

        # Initialize vectors to store patches and their center positions
        patches = []
        centers = []

        # Slide the window through the entire field
        for x in range(
            int((self.windowSize - 1) / 2), self.data.shape[0] - int((self.windowSize - 1) / 2), 1
        ):
            for y in range(
                int((self.windowSize - 1) / 2),
                self.data.shape[1] - int((self.windowSize - 1) / 2),
                1,
            ):
                # Define min and max coordinates of the patch around point (x, y)
                xmin = x - int((self.windowSize - 1) / 2)
                xmax = x + int((self.windowSize - 1) / 2) + 1
                ymin = y - int((self.windowSize - 1) / 2)
                ymax = y + int((self.windowSize - 1) / 2) + 1

                if self.coords[x, y] is None:
                    continue

                # Extract patch
                patch = self.data[xmin:xmax, ymin:ymax, :]

                # Add patch to batch and save position
                # print("Saving block at position X: " + str(x) + ", Y: " + str(y))
                patches.append(patch)
                centers.append((x, y))

                right = False
                bottom = False
                # Add rightmost patch
                if (ymax < self.data.shape[1]) and ((ymax + 1) > self.data.shape[1]):
                    patch = self.data[xmin:xmax, self.data.shape[1] - self.windowSize :, :]
                    print(
                        "Saving block at position X: "
                        + str(x)
                        + ", Y: "
                        + str(int(self.data.shape[1] - 0.5 - self.windowSize / 2))
                    )
                    patches.append(patch)
                    centers.append((x, int(self.data.shape[1] - 0.5 - self.windowSize / 2)))
                    right = True

                # Add bottom patch
                if (xmax < self.data.shape[0]) and ((xmax + 1) > self.data.shape[0]):
                    patch = self.data[self.data.shape[0] - self.windowSize :, ymin:ymax, :]
                    print(
                        "Saving block at position X: "
                        + str(int(self.data.shape[0] - 0.5 - self.windowSize / 2))
                        + ", Y: "
                        + str(y)
                    )
                    patches.append(patch)
                    centers.append((int(self.data.shape[0] - 0.5 - self.windowSize / 2), y))
                    bottom = True

                # Add rightmost bottom patch
                if right and bottom:
                    patch = self.data[
                        self.data.shape[0] - self.windowSize :,
                        self.data.shape[1] - self.windowSize :,
                        :,
                    ]
                    print(
                        "Saving block at position X: "
                        + str(int(self.data.shape[0] - 0.5 - self.windowSize / 2))
                        + ", Y: "
                        + str(int(self.data.shape[1] - 0.5 - self.windowSize / 2))
                    )
                    patches.append(patch)
                    centers.append(
                        (
                            int(self.data.shape[0] - 0.5 - self.windowSize / 2),
                            int(self.data.shape[1] - 0.5 - self.windowSize / 2),
                        )
                    )

        patches = np.array(patches)
        # Reshape data as 4-D TENSOR
        patches = np.reshape(
            patches, (patches.shape[0], patches.shape[1], patches.shape[2], patches.shape[3], 1)
        )
        # Transpose dimensions to fit Pytorch order
        patches = patches.transpose((0, 4, 3, 1, 2))

        return patches, centers

    def modifyPrescription(self, presc_path=None, method="uniform", n_rate=None):
        """Used a modified prescription map before predicting yield.
        @param presc_path: Path of the prescription map.
        @param method: Options: 'FEAMOO', 'CCEAMOO', 'NSGA2', 'uniform'.
        @param n_rate: If method='uniform', specify the uniform nitrogen rate that will be applied to the entire field.
        """
        if method == "uniform":
            # Set a prescription map with uniform values of nitrogen
            n_map = self.data[:, :, 0] * 0
            n_map[self.mask_field == 1] = n_rate
        else:
            # Load data
            n_map, _, _ = DataLoader.loadData(
                path=presc_path, cov=["N"], field=self.field, read_column=True
            )
            n_map = n_map[:, :, 0]

            # Points outside the boundary should be assigned the base-rate nitrogen
            n_map[(n_map == 0) & (self.data[:, :, 2] != 0)] = 100

        # Replace nitrogen map
        self.data[:, :, 0] = n_map

    def trainPreviousYears(
        self,
        batch_size=96,
        epochs=500,
        modelType="Hyper3DNet",
        print_process=True,
        objective="yld",
        beta_=None,
    ):
        """Train using all the data from the selected years.
        @param batch_size: Size of the mini-batches used for training (used for the CNNs).
        @param epochs: Number pf epochs used for training (used for the CNNs).
        @param modelType: Name of the model that will be used. Options: 'Hyper3DNet', 'Hyper3DNetQD',
                          'Russello', 'CNNLF', 'RF', 'GAM', and 'MLRegression'.
        @param print_process: If True, shows the evolution of the performance while training.
        @param objective: Name of the target. Default: 'yld' (Yield).
        @param beta_: Hyperparameters used for generation of the prediction intervals."""

        # Load training data of the previous years
        trainx, train_y = self.dataLoader.create_training_set(objective=objective)
        self.nbands = trainx.shape[2]

        print("\n******************************")
        print("Start Training: ")
        print("******************************")
        # Normalize features using the training set
        trainx, self.maxs, self.mins = utils.normalize(trainx)
        # Normalize outputs using the training set
        train_y, self.maxY, self.minY = utils.minMaxScale(train_y)

        self.model = self.init_model(modelType=modelType)  # Initialize ML model
        self.path_model = (
            "output/"
            + "Model-"
            + modelType
            + "-"
            + self.field
            + "--Objective-"
            + objective
            + "/"
            + modelType
            + "-"
            + self.field
            + "--Objective-"
            + objective
        )
        if not os.path.exists(os.path.dirname(self.path_model)):
            os.mkdir(os.path.dirname(self.path_model))

        # Save statistics
        np.save(
            "output/"
            + "Model-"
            + modelType
            + "-"
            + self.field
            + "--Objective-"
            + objective
            + "/"
            + self.field
            + "_statistics.npy",
            [self.maxs, self.mins, self.maxY, self.minY],
        )

        # Train the model using the current training-validation split
        return self.model.trainPrevious(
            trainx,
            train_y,
            batch_size,
            epochs,
            self.path_model,
            print_process,
            beta_=beta_,
            yscale=[self.maxY, self.minY],
        )

    def predict(
        self,
        uncertainty=False,
        stats_path=None,
        model_path=None,
        modelType="Hyper3DNet",
        objective="yld",
        Nrate=None,
        clearBorder=False,
    ):
        """Predict the yield map using a sliding window.
        @param uncertainty: If True, calculate and return prediction intervals.
        @param stats_path: Path that contains the statistics of the training set.
        @param model_path: Path that contains the trained model (Optional. Otherwise, the model needs to be trained).
        @param modelType: Name of the model that will be used. Options: 'Hyper3DNet', 'Hyper3DNetQD', 'AdaBoost',
                          'Russello', 'CNNLF', 'SAE', 'RF', 'GAM', and 'MLRegression'.
        @param objective: Name of the target. Default: 'yld' (Yield).
        @param Nrate: If not None, it is the uniform N rate used for prediction.
        @param clearBorder: If True, remove the predictions from the borders to avoid uncertain results
        """

        self.load_pred_data(
            objective=objective, modifyNRate=Nrate, clearBorder=clearBorder
        )  # Load prediction data

        # Load model if there is one
        self.model = self.init_model(modelType=modelType)  # Initialize ML model
        print("Loading model...")
        if model_path is None:
            # If the model and the statistics are not provided, check if they are in the temp file
            self.path_model = (
                "output/"
                + "Model-"
                + modelType
                + "-"
                + self.field
                + "--Objective-"
                + objective
                + "/"
                + modelType
                + "-"
                + self.field
                + "--Objective-"
                + objective
            )
            if os.path.exists(self.path_model):
                self.model.loadModel(path=self.path_model)
            else:
                sys.exit(
                    "There is no trained model saved. You need to execute the trainPreviousYear method first."
                )
        else:
            self.path_model = model_path
            self.model.loadModel(path=model_path)

        # In case the statistics are not provided, read the training set to calculate the statistics
        if stats_path is None:
            # Try to check if there's a file in the temp folder with the statistics of the field
            stats_path = (
                "output/"
                + "Model-"
                + modelType
                + "-"
                + self.field
                + "--Objective-"
                + objective
                + "/"
                + self.field
                + "_statistics.npy"
            )
            if os.path.exists(stats_path):
                [self.maxs, self.mins, self.maxY, self.minY] = np.load(
                    stats_path, allow_pickle=True
                )
            else:  # Or calculate them
                # Load training data of the previous years
                trainx, train_y = self.dataLoader.create_training_set()
                # Calculate statistics using the training set
                _, self.maxs, self.mins = utils.normalize(trainx)
                _, self.maxY, self.minY = utils.minMaxScale(train_y)
                del trainx
                del train_y  # Remove from memory
        else:
            if os.path.exists(stats_path):
                # Read statistics from file
                [self.maxs, self.mins, self.maxY, self.minY] = np.load(
                    stats_path, allow_pickle=True
                )
            else:
                sys.exit("There provided path does not exist.")

        # Remove areas affected by fire in sec35middle
        if self.field == "sec35middle":
            self.mask_field[83:106, 46:] = 0
            self.mask_field[102:116, 43:60] = 0
        self.coords[self.mask_field == 0] = None

        # Extract patches and their centers
        patches, centers = self.extract2DPatches()

        # Predict yield values for each patch in the batch
        uncPatches = None
        if uncertainty:
            yieldPatches, uncPatches = np.array(
                self.model.predictSamplesUncertainty(
                    datasample=patches,
                    maxs=self.maxs,
                    mins=self.mins,
                    batch_size=256,
                    MC_samples=50,
                )
            )
        else:
            yieldPatches = np.array(
                self.model.predictSamples(
                    datasample=patches, maxs=self.maxs, mins=self.mins, batch_size=256
                )
            )

        # ####################################################################
        # Reconstruct map one block at a time. Check if there is overlapping.
        # ####################################################################
        yield_map = np.zeros((self.data.shape[0], self.data.shape[1]))  # Initialize empty yield map
        PI_map = np.zeros(
            (self.data.shape[0], self.data.shape[1])
        )  # Initialize empty confidence map
        temp_yield_map = np.frompyfunc(list, 0, 1)(
            np.empty((self.data.shape[0], self.data.shape[1]), dtype=object)
        )
        # Initialize variables for when the upper and lower bounds are given instead of the predicted yield
        y_u, y_l, temp_y_u, temp_y_l, temp_y_p = None, None, None, None, None
        if modelType == "Hyper3DNetQD":
            y_u = np.zeros((self.data.shape[0], self.data.shape[1]))  # Store upper bounds
            y_l = np.zeros((self.data.shape[0], self.data.shape[1]))  # Store lower bounds
            temp_y_u = np.frompyfunc(list, 0, 1)(
                np.empty((self.data.shape[0], self.data.shape[1]), dtype=object)
            )
            temp_y_l = np.frompyfunc(list, 0, 1)(
                np.empty((self.data.shape[0], self.data.shape[1]), dtype=object)
            )
            temp_y_p = np.frompyfunc(list, 0, 1)(
                np.empty((self.data.shape[0], self.data.shape[1]), dtype=object)
            )

        for i, ypatch in enumerate(yieldPatches):
            # Get original coordinates of the center of ypatch
            (x, y) = centers[i]
            # Define min and max coordinates of the patch around point (x, y)
            xmin = x - int((self.outputSize - 1) / 2)
            ymin = y - int((self.outputSize - 1) / 2)
            # Put ypatch in temp_map considering its original position
            if self.outputSize == 1:
                if modelType in ["MLRegression", "AdaBoost", "SAE", "RF", "GAM"]:
                    temp_yield_map[xmin, ymin].append(ypatch)
                    if uncertainty:
                        PI_map[xmin, ymin] = uncPatches[i]
                else:
                    if modelType == "Hyper3DNetQD":
                        temp_y_u[xmin, ymin] += list(ypatch[0, :, :])
                        temp_y_l[xmin, ymin] += list(ypatch[1, :, :])
                        temp_y_p[xmin, ymin] += list(ypatch[2, :, :])
                    else:
                        if str(type(ypatch[0])) == "<class 'numpy.float64'>":
                            temp_yield_map[xmin, ymin].append(ypatch)
                        else:
                            temp_yield_map[xmin, ymin] += list(ypatch[0, :])
            else:
                for patch_x in range(ypatch.shape[0]):
                    for patch_y in range(ypatch.shape[1]):
                        if modelType == "Hyper3DNetQD":
                            if str(type(ypatch[patch_x, patch_y])) == "<class 'numpy.float64'>":
                                temp_y_u[xmin + patch_x, ymin + patch_y].append(ypatch[0])
                                temp_y_l[xmin + patch_x, ymin + patch_y].append(ypatch[1])
                                temp_y_p[xmin + patch_x, ymin + patch_y].append(ypatch[2])
                            else:
                                temp_y_u[xmin + patch_x, ymin + patch_y] += list(
                                    ypatch[0, patch_x, patch_y]
                                )
                                temp_y_l[xmin + patch_x, ymin + patch_y] += list(
                                    ypatch[1, patch_x, patch_y]
                                )
                                temp_y_p[xmin + patch_x, ymin + patch_y] += list(
                                    ypatch[2, patch_x, patch_y]
                                )
                        else:
                            if str(type(ypatch[patch_x, patch_y])) == "<class 'numpy.float64'>":
                                temp_yield_map[xmin + patch_x, ymin + patch_y].append(
                                    ypatch[patch_x, patch_y]
                                )
                            else:
                                temp_yield_map[xmin + patch_x, ymin + patch_y] += list(
                                    ypatch[patch_x, patch_y]
                                )

        # Average overlapping regions
        for i in range(self.data.shape[0]):
            for j in range(self.data.shape[1]):
                if modelType == "Hyper3DNetQD":
                    if not temp_y_u[i, j]:
                        continue
                    # Calculate mean upper and lower bounds
                    up = np.mean(temp_y_u[i, j])
                    lo = np.mean(temp_y_l[i, j])
                    # Calculate mean response
                    yield_map[i, j] = np.mean(temp_y_p[i, j])
                    # Calculate uncertainty width
                    PI_map[i, j] = up - lo
                    y_u[i, j] = up
                    y_l[i, j] = lo
                else:
                    # Discard zeroes
                    temp_vec = [v for v in temp_yield_map[i, j] if v != 0]
                    if len(temp_vec) == 0:
                        continue
                    # Calculate mean
                    yield_map[i, j] = np.mean(temp_vec)
                    # Obtain the standard deviation of each pixel for CNNs methods using MCDropout
                    if uncertainty and (modelType in ["Hyper3DNet", "Russello", "CNNLF"]):
                        PI_map[i, j] = np.std(temp_vec)  # This is the model uncertainty (variance)

        # Discard results that are outside the field
        yield_map = np.multiply(yield_map, self.mask_field)
        yield_map = utils.reverseMinMaxScale(yield_map, maxs=self.maxY, mins=self.minY)
        yield_map[np.where(yield_map < 0)] = 0
        PI_map = np.multiply(PI_map, self.mask_field)

        # If using MCDropout, add the data noise variance
        if uncertainty and modelType not in ["MLRegression", "Hyper3DNetQD"]:
            # Load validation MSE
            with open(self.path_model + "_validationMSE", "rb") as f:
                val_MSE = pickle.load(f)
            PI_map = np.sqrt(PI_map**2 + val_MSE)

        # Save maps as shapefiles
        coords = np.reshape(
            self.coords, (self.coords.shape[0] * self.coords.shape[1])
        )  # Vectorize coordinates map
        yield_vector = np.reshape(
            yield_map, (yield_map.shape[0] * yield_map.shape[1])
        )  # Vectorize yield map
        yield_vector = [y for y, cr in zip(yield_vector, coords) if cr is not None]
        if modelType == "Hyper3DNetQD":
            yu_vector = np.reshape(y_u, (y_u.shape[0] * y_u.shape[1]))  # Vectorize upper bound map
            yu_vector = [y for y, cr in zip(yu_vector, coords) if cr is not None]
            yl_vector = np.reshape(y_l, (y_l.shape[0] * y_l.shape[1]))  # Vectorize lower bound map
            yl_vector = [y for y, cr in zip(yl_vector, coords) if cr is not None]
            results = [yield_vector, yu_vector, yl_vector]
        else:
            results = [yield_vector]
        coords = [cr for cr in coords if cr is not None]
        shapepath = (os.path.dirname(self.path_model) + "_Shapefile").replace("Model-", "")
        utils.createShapefile(coords=coords, columns=results, filepath=shapepath, obj=objective)

        # Return yield map
        if not uncertainty:
            return yield_map
        # Or return prediction and upper and lower bounds
        else:
            if modelType == "Hyper3DNetQD":
                y_u = utils.reverseMinMaxScale(y_u, maxs=self.maxY, mins=self.minY)
                y_l = utils.reverseMinMaxScale(y_l, maxs=self.maxY, mins=self.minY)
                PI_map = utils.reverseMinMaxScale(PI_map, maxs=self.maxY, mins=self.minY)
                return yield_map, y_u * self.mask_field, y_l * self.mask_field, PI_map
            else:
                # Include the z-multiplier
                PI_map *= 1.96
                return yield_map, yield_map + PI_map, yield_map - PI_map, PI_map * 2

    def NvsY_generation(self, n_min=0, n_max=150, n_samples=30, uncertainty=False):
        """Predict the yield map using n_rates = [n_min, n_min + 5, ... , n_max]"""

        ymaps = np.zeros((self.data.shape[0], self.data.shape[1], n_samples))
        y_u = np.zeros((self.data.shape[0], self.data.shape[1], n_samples))
        y_l = np.zeros((self.data.shape[0], self.data.shape[1], n_samples))
        for i, n in enumerate(range(n_min, n_max, int((n_max - n_min) / n_samples))):
            print("Predicting for N rate = " + str(n))
            y_map = self.predict(uncertainty=uncertainty, Nrate=n)
            if not uncertainty:
                ymaps[:, :, i] = y_map
            else:
                ymaps[:, :, i] = y_map[0]
                y_u[:, :, i] = y_map[1]
                y_l[:, :, i] = y_map[2]

        if uncertainty:
            return [ymaps, y_u, y_l]
        else:
            return [ymaps]

    def EONR(self, pC, pN, n_min=0, n_max=150, n_samples=150):
        """Simple first derivative method used to calculate the economic optimal net return (EONR)
        @param pC: price of the crop.
        @param pN: price of he N fertilizer
        @param n_min: Initial N rate use for the NvsY curve generation.
        @param n_max: Final N rate use for the NvsY curve generation.
        @param n_samples: Number of samples used for the NvsY curve generation"""

        # Obtain the yield prediction using different N rates
        ymaps = self.NvsY_generation(n_min, n_max, n_samples, uncertainty=False)[0]

        EONR = np.zeros((ymaps.shape[0], ymaps.shape[1]))

        # Repeat for each point in the field
        for x in range(ymaps.shape[0]):
            for y in range(ymaps.shape[1]):
                if sum(ymaps[x, y, :]) > 0:  # Check if it's a point of the field
                    # Calculate net return and price of fertilizer
                    Nrates = np.arange(n_min, n_max, int((n_max - n_min) / n_samples))
                    norm_min = np.min(ymaps[x, y, :])
                    norm_max = np.max(ymaps[x, y, :])
                    norm_data = (ymaps[x, y, :] - norm_min) / (norm_max - norm_min)
                    f = splrep(Nrates, norm_data, k=5, s=11)
                    smooth_data = splev(Nrates, f)
                    smooth_data = smooth_data * (norm_max - norm_min) + norm_min
                    NR = pC * smooth_data - pN * Nrates

                    # Calculate first derivative
                    dP = np.diff(NR) / np.diff(Nrates)

                    # Check where the derivative is higher or equal than pN
                    eonrs = np.where(dP >= pN)[0]
                    EONR[x, y] = eonrs[
                        -1
                    ]  # Keep the last point with derivative higher than pN (max yield)
        return EONR


if __name__ == "__main__":
    #####################################################
    # Corn Field Simulation
    #####################################################
    filepath = (
        "C:\\Users\\w63x712\\Documents\\Machine_Learning\\OFPE\\Data\\CSV_Files\\sim_data.csv"
    )
    fieldname = ""
    cvars = [
        "N",
        "par1",
        "par2",
        "par3",
        "par4",
        "par5",
        "par6",
        "par7",
        "par8",
        "par9",
        "par10",
        "par11",
        "par12",
        "par13",
        "par14",
    ]
    modelname = "Hyper3DNet"
    goal = "yld"
    # 10-fold cross validation
    RMSE, RMSE_EONR = [], []
    prediction, target = None, None
    for nt in range(10):
        print(
            "************************************************************************************************"
        )
        print("Fold " + str(nt + 1) + " / 10")
        print(
            "************************************************************************************************"
        )
        tyears = list(np.arange(1, 11))
        tyears.remove(10 - nt)
        pyear = 10 - nt
        predictor = YieldMapPredictor(
            filename=filepath, field=fieldname, training_years=tyears, pred_year=pyear, cov=cvars
        )
        # Train and validate
        # predictor.trainPreviousYears(epochs=500, batch_size=64, modelType=modelname, objective=goal)
        prediction = np.clip(
            predictor.predict(modelType=modelname, objective=goal), a_min=0, a_max=2e4
        )
        # Compare to the ground-truth and calculate the RMSE
        target, _, _, _ = loadData(
            path=filepath,
            field=fieldname,
            year=10 - nt,
            cov=cvars,
            inpaint=True,
            inpaint_features=False,
            base_N=120,
            test=False,
            obj=goal,
        )
        RMSE.append(utils.mse(prediction, target) ** 0.5)
        print("Validation RMSE = " + str(RMSE[nt]))

        # Estimate the EONR and compare it to the ground-truth
        EONR_est = predictor.EONR(pC=0.246063, pN=2.204624, n_min=0, n_max=260, n_samples=260)
        # Compare to the ground-truth and calculate the RMSE
        EONR_target, _, _, _ = loadData(
            path=filepath,
            field=fieldname,
            year=10 - nt,
            cov=cvars,
            inpaint=True,
            inpaint_features=False,
            base_N=120,
            test=False,
            obj="EONR",
        )
        RMSE_EONR.append(utils.mse(EONR_est, EONR_target) ** 0.5)
        print("EONR Validation RMSE = " + str(RMSE_EONR[nt]))

    # Plot lat results for reference
    plt.figure()
    plt.imshow(prediction)
    plt.title("Predicted yield map")
    plt.axis("off")
    plt.figure()
    plt.imshow(target)
    plt.title("Ground-truth yield map")
    plt.axis("off")
