import cv2
import sys
import numpy as np
import pandas as pd
from scipy import ndimage
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# from itertools import cycle, islice


#######################################################################################################################
# Static functions
#######################################################################################################################
def autopatches(data, window=5, overlap=0.75, plot=False):
    """Function used to automatically extract patches from the data
    @param data: Numpy array with containing the data that will be cropped. The first channel is the target variable.
    @param window: Size of the square patches.
    @param overlap: Percentage of overlap allowed between patches.
    @param plot: If True, it plots the target raster and the patches selected."""

    ###################################################################
    # Step 1: Detect the number of connected components within the data
    ###################################################################
    targ = data[0, :, :].copy()
    sats = data[8, :, :].copy()
    # Create binary mask
    bmask = np.ones((targ.shape[0], targ.shape[1]), dtype=np.uint8)
    bmask[np.where(targ <= 0)] = 0  # If there is useful information=1, otherwise=0
    # Label image
    num_labels, labels = cv2.connectedComponents(bmask)
    ax, fig = None, None
    if plot:
        # Plot target
        fig, ax = plt.subplots(1)
        ax.imshow(targ)

    ###################################################################
    # Step 2: Extract patches for each component
    ###################################################################
    visited = np.zeros(
        (targ.shape[0], targ.shape[1]), dtype=np.uint8
    )  # track the points that were visited
    centers = np.zeros((targ.shape[0], targ.shape[1]), dtype=np.uint8)  # track the selected centers
    list_patches = []  # Array that will contain all selected patches
    for nc in range(1, num_labels):
        # Step 2.1: Evaluate if this component is big enough to be considered
        cords = np.where(labels == nc)
        xcords = cords[0]
        ycords = cords[1]
        width = np.max(xcords) - np.min(xcords)
        height = np.max(ycords) - np.min(ycords)
        if width < window or height < window:
            continue

        # For each point in the component, create a patch of (window x window) pixels around it
        # and verify if it is inside the contour of the component and if it does not exceed the desired overlap.
        for point in zip(cords[0], cords[1]):
            # Define min and max coordinates of the patch around "point"
            xmin = point[0] - int((window - 1) / 2)
            xmax = point[0] + int((window - 1) / 2) + 1
            ymin = point[1] - int((window - 1) / 2)
            ymax = point[1] + int((window - 1) / 2) + 1
            # Step 2.2: Check if the patch is within the bounding box
            if (
                xmin < np.min(xcords)
                or ymin < np.min(ycords)
                or xmax > np.max(xcords)
                or ymax > np.max(ycords)
            ):
                continue
            # Step 2.3: Check if the patch contains points without information (i.e. if contains background pixels)
            if (
                len(np.where(targ[xmin:xmax, ymin:ymax] == -1)[0]) > 0
                or len(np.where(targ[xmin:xmax, ymin:ymax] <= 5)[0]) > 10
                or len(np.where(sats[xmin:xmax, ymin:ymax] == -1)[0]) > 0
                or len(np.where(data[1, :, :][xmin:xmax, ymin:ymax] == -1)[0]) > 0
            ):
                continue
            # Step 2.4: Check if the patch exceeds the maximum overlap allowed
            if np.sum(visited[xmin:xmax, ymin:ymax]) / (window * window) > overlap:
                continue
            # Step 2.5: Check if there is a distance of at least (window - 1) / 2 w.r.t to the closest center
            neighbors = np.where(centers[xmin:xmax, ymin:ymax] == 1)
            mindist = np.infty
            for center in zip(neighbors[0], neighbors[1]):
                newdist = np.sqrt(center[0] ** 2 + center[1] ** 2)
                if newdist < mindist:
                    mindist = newdist
            if mindist < (window - 1) / 2:
                continue

            # Updated the matrix of visited points and centers
            visited[xmin:xmax, ymin:ymax] = np.ones((window, window))
            centers[point[0], point[1]] = 1

            # Step 2.5: Add patch to list
            list_patches.append(data[:, xmin:xmax, ymin:ymax])

            # Show selected patches
            if plot:
                # Paint the current patch
                rect = patches.Rectangle(
                    (ymin - 0.5, xmin - 0.5),
                    window,
                    window,
                    linewidth=1,
                    edgecolor="r",
                    facecolor="none",
                )
                # Add the patch to the Axes
                ax.add_patch(rect)
                fig.canvas.draw()

    return list_patches


def loadData(
    path=None,
    obj="yld",
    year=2018,
    field="",
    cov=None,
    mode="AggRADARPrec",
    inpaint=True,
    inpaint_features=False,
    base_N=120,
    read_column=False,
    test=False,
):
    """Load aggregated data in .CSV format and Sentinel-1 images
    @param path: Specify the absolute path of the CSV file that will be read. It can be also a FileStorage object.
    @param obj: Specify the type of target that will be evaluated. Options: 'yld', 'pro'.
    @param year: Year that will be evaluated. Options: '2016', '2017', '2018', '2019', or '2020'.
    @param field: Field that will be evaluated.
    @param cov: List of the names of the desired covariates. E.g. ['aa_n', 'slope', 'elev', 'aspect_rad', 'prec_cy_g'].
    @param mode: Define the features that will be read. Options: 'All', 'AggRADAR', 'AllPrec'.
    @param inpaint: If True, use in-painting to handle missing yield information.
    @param inpaint_features: If True, use in-painting to handle missing information of the features.
    @param base_N: Farmer selected Nitrogen rate.
    @param read_column: If True, read all the data from the specified column only (no target or year is considered).
    @param test: If True, ignore the target column and retrieve only the date.
    return 'target', a np array containing a raster with the values of interest, and 'data', a multidimensional array
        that contains the corresponding covariates for each point.
    """

    # Set default covariates that will be read depending on the selected mode
    if mode == "All":
        covariates = [
            "aa_n",
            "slope",
            "elev",
            "tpi",
            "aspect_rad",
            "prec_cy_g",
            "ndvi_py_f",
            "ndwi_py_f",
            "vv_cy_f",
            "vh_cy_f",
        ]
    elif mode == "AggRADAR":
        covariates = ["aa_n", "slope", "elev", "tpi", "aspect_rad", "vv_cy_f", "vh_cy_f"]
    elif mode == "AggRADARPrec":
        covariates = [
            "aa_n",
            "slope",
            "elev",
            "tpi",
            "aspect_rad",
            "prec_cy_g",
            "vv_cy_f",
            "vh_cy_f",
        ]
    else:
        sys.exit("The possible combinations are 'All', 'AggRADAR', and 'AggRADARPrec'.")

    if cov is None or cov == ["N"]:  # Set default features in case it is not specified.
        covB = covariates
    else:
        covB = cov

    # Read the data file to know the original dimensions
    if isinstance(path, str):
        data = pd.read_csv(path, low_memory=False)
        df = pd.DataFrame(data)
    else:
        df = path
    # In addition to the selected features, we also read the coordinates, the year, and the desired target
    if not test:
        df = df[covB + ["x", "y", "year", "field", "cell_id", obj]]
    else:
        df = df[covB + ["x", "y", "year", "field", "cell_id"]]

    if field != "":
        df = df[df["field"] == field]
    else:
        field = "nan"
    # Sort unique UTM XY coordinates
    rows = np.round(df["y"].unique(), 6)
    rows.sort()
    cols = np.round(df["x"].unique(), 6)
    cols.sort()

    # Transform XY coordinates to indexes
    data = np.ones((rows.shape[0], cols.shape[0], len(covB))) * -2
    target = (
        np.ones(
            (
                rows.shape[0],
                cols.shape[0],
            )
        )
        * -2
    )
    cellids = np.empty((rows.shape[0], cols.shape[0]), dtype=object)
    XYcoords = np.empty((rows.shape[0], cols.shape[0]), dtype=object)
    simple_coords = []
    for d in df.iterrows():
        if not read_column:
            if d[1]["year"] == year and str(d[1]["field"]) == field:
                xcord = np.where(rows == np.round(d[1]["y"], 6))[0][0]
                ycord = np.where(cols == np.round(d[1]["x"], 6))[0][0]
                # If there is missing values, fill with -1
                if not test:
                    if np.isnan(d[1][obj]):  # Check the target
                        d[1][obj] = -1
                for f in covB:  # Check each one of the features
                    if np.isnan(d[1][f]):
                        d[1][f] = -1
                if not test:
                    target[
                        xcord,
                        ycord,
                    ] = d[
                        1
                    ][obj]
                cellids[xcord, ycord] = d[1]["cell_id"]
                XYcoords[xcord, ycord] = [d[1]["x"], d[1]["y"]]
                if [d[1]["x"], d[1]["y"]] not in simple_coords:
                    simple_coords.append([d[1]["x"], d[1]["y"]])
                if not test:
                    d2 = d[1].drop(["x", "y", "year", "field", "cell_id", obj])
                else:
                    d2 = d[1].drop(["x", "y", "year", "field", "cell_id"])
                data[xcord, ycord, :] = d2.iloc[:]
        elif d[1]["field"] == field:
            xcord = np.where(rows == np.round(d[1]["y"], 6))[0][0]
            ycord = np.where(cols == np.round(d[1]["x"], 6))[0][0]
            # If there is missing values, fill with -1
            for f in covB:  # Check each one of the features
                if np.isnan(d[1][f]):
                    d[1][f] = -1
            cellids[xcord, ycord] = d[1]["cell_id"]
            XYcoords[xcord, ycord] = [d[1]["x"], d[1]["y"]]
            if [d[1]["x"], d[1]["y"]] not in simple_coords:
                simple_coords.append([d[1]["x"], d[1]["y"]])
            d2 = d[1].drop(["x", "y", "field", "cell_id"])
            data[xcord, ycord, :] = d2.iloc[:]

    # Flip the rasters horizontally
    target = np.flip(target, 0)
    data = np.flip(data, 0)
    cellids = np.flip(cellids, 0)
    XYcoords = np.flip(XYcoords, 0)

    # Apply in-painting to handle missing information of the target
    if not test:
        temp, maskfield = inpainting(target)
        if inpaint:
            target = temp
    if inpaint_features:
        for d in range(len(covB)):  # Always use in-painting for the features
            if covB[d] != "ndwi_py_f" and covB[d] != "vh_cy_f" and covB[d] != "vv_cy_f":
                data[:, :, d], _ = inpainting(data[:, :, d])

    # Set background to 0
    target[target == -2] = 0
    data[data == -2] = 0

    # Missing nitrogen data at the boundaries is be replaced by the base nitrogen rate
    N = data[:, :, 0]
    N[N == -1] = base_N
    data[:, :, 0] = N

    # Apply median filter to radar images
    if "RADAR" in mode:
        data[:, :, -1] = ndimage.median_filter(data[:, :, -1], size=3)
        data[:, :, -2] = ndimage.median_filter(data[:, :, -2], size=3)

    if not read_column:
        if not test:
            return target.astype("float32"), data, cellids, XYcoords, simple_coords
        else:
            return data, cellids, XYcoords, simple_coords
    else:
        return data, cellids, XYcoords, simple_coords


def inpainting(M):
    """Use in-painting to handle missing information in raster M"""
    # Create binary mask to detect field objects
    maskfields = (M * 0).astype(np.uint8)
    maskfields[np.where(M >= 0)] = 1
    # Close object border
    maskfields = cv2.morphologyEx(maskfields, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8))
    maskfields[0 : maskfields.shape[0] - 1, 0 : maskfields.shape[1] - 1] = maskfields[
        1 : maskfields.shape[0], 1 : maskfields.shape[1]
    ]  # Compensate the shift produced after closing
    # Set the first and last rows and columns to 0 so that the background can be represented as one connected component
    maskfields[0, :] = 0
    maskfields[-1, :] = 0
    maskfields[:, 0] = 0
    maskfields[:, -1] = 0
    # Detect background
    backglabels = cv2.connectedComponents(1 - maskfields)
    biggestObjectCount = 0
    backgroundLabel = None
    for b in range(1, backglabels[0]):
        count = len(np.where(backglabels[1] == b))
        if count > biggestObjectCount:
            backgroundLabel = b
            biggestObjectCount = count
    for b in range(1, backglabels[0]):
        if b != backgroundLabel:
            xm, ym = np.where(backglabels[1] == b)
            maskfields[xm, ym] = 1
    # Create binary mask for missing objects only if they're inside a field object
    mask = (M * 0).astype(np.uint8)
    mask[np.where(M < 0)] = 1
    mask = mask * maskfields
    # In-paint
    M = cv2.inpaint(M.astype(np.float32), mask, 3, cv2.INPAINT_TELEA)
    return M, maskfields


#######################################################################################################################
# Class definition
#######################################################################################################################
class DataLoader:
    def __init__(
        self,
        field: str,
        training_years: list,
        pred_year: int,
        mode="AggRADARPrec",
        cov=None,
        filename=None,
    ):
        """Initialize data loader class
        @param filename: Path containing the data (CSV)
        @param field: Name of the specific field that will be analyzed.
        @param training_years: Declare the years of data that will be used for training.
        @param pred_year: The year that will be used for prediction.
        @param mode: Declare the type of variable combination that will be used.
        @param cov: Custom list of the names of the desired covariates.
        """
        self.filename = filename
        self.field = field
        self.training_years = training_years
        self.pred_year = pred_year
        self.mode = mode
        self.cov = cov

    def create_training_set(self, objective="yld"):
        """Create a training set from the training years using 5x5 patches"""
        # Extract training patches year by year
        X = []
        for year in self.training_years:
            # Read the CSV file
            Yd, Xd, _, _ = loadData(
                path=self.filename,
                field=self.field,
                year=int(year),
                cov=self.cov,
                inpaint=True,
                inpaint_features=False,
                base_N=120,
                mode=self.mode,
                obj=objective,
            )
            # Combine target and data into a data cube
            rastercollection = [Yd] + list(Xd.transpose((2, 0, 1)))
            # Format list as multi-dimensional array
            rastercollection = np.array(rastercollection)
            # Extract patches
            pa = autopatches(rastercollection, window=5, plot=False)
            X = X + pa

        # Separate target and covariates
        X = np.array(X)
        Y = X[:, 0, :, :]
        X = X[:, 1:, :, :]

        # Reshape data as 4-D TENSOR
        X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2], X.shape[3], 1))
        # Transpose dimensions to fit Pytorch order
        X = X.transpose((0, 4, 1, 2, 3))

        # # Count the number of samples for each nitrogen rate level
        # range0_20 = []
        # range20_40 = []
        # range40_60 = []
        # range60_80 = []
        # range80_100 = []
        # range100_120 = []
        # range120_150 = []
        # for ip, s in enumerate(X):
        #     average_nitrogen = np.average(s[0, 0, 1:4, 1:4])
        #     if len(np.where(s[0, 0, 1:4, 1:4:] < 20)[0]) > 3:
        #         range0_20.append(ip)
        #     elif len(np.where(120 <= s[0, 0, 1:4, 1:4])[0]) > 3:
        #         range120_150.append(ip)
        #     else:
        #         if 20 <= average_nitrogen < 40:
        #             range20_40.append(ip)
        #         elif 40 <= average_nitrogen < 60:
        #             range40_60.append(ip)
        #         elif 60 <= average_nitrogen < 80:
        #             range60_80.append(ip)
        #         elif 80 <= average_nitrogen < 100:
        #             range80_100.append(ip)
        #         elif 100 <= average_nitrogen < 120:
        #             range100_120.append(ip)
        #
        # # Repeat under-represented samples to obtain a uniform distribution
        # max_n = int(np.max([len(range0_20), len(range20_40), len(range40_60), len(range60_80), len(range80_100),
        #                     len(range100_120), len(range120_150)]))
        # elements = list(islice(cycle(range0_20), max_n))
        # elements = list(islice(cycle(range40_60), max_n)) + elements
        # elements = list(islice(cycle(range60_80), max_n)) + elements
        # elements = list(islice(cycle(range80_100), max_n)) + elements
        # elements = list(islice(cycle(range100_120), max_n)) + elements
        # elements = list(islice(cycle(range120_150), max_n)) + elements
        # temp = np.zeros((len(elements), X.shape[1], X.shape[2], X.shape[3], X.shape[4]))
        # temp2 = np.zeros((len(elements), Y.shape[1], Y.shape[2]))
        # for n in range(len(elements)):
        #     temp[n, :, :, :, :] = X[elements[n], :, :, :, :]
        #     temp2[n, :, :] = Y[elements[n], :, :]
        # X, Y = temp, temp2

        # Shuffle dataset
        np.random.seed(seed=7)  # Initialize seed to get reproducible results
        ind = [x for x in range(X.shape[0])]
        np.random.shuffle(ind)
        X = X[ind]
        Y = Y[ind]
        return X, Y

    def load_raster(self, objective="yld"):
        return loadData(
            path=self.filename,
            field=self.field,
            year=int(self.pred_year),
            cov=self.cov,
            inpaint=True,
            inpaint_features=False,
            base_N=120,
            mode=self.mode,
            test=True,
            obj=objective,
        )


if __name__ == "__main__":
    # Test loading real data
    ex_path = (
        "C:\\Users\\w63x712\\Documents\\Machine_Learning\\OFPE\\Data\\CSV_Files\\farmers\\"
        "broyles_10m_yldDat_with_sentinel.csv"
    )
    loader = DataLoader(ex_path, field="sec35middle", training_years=[2016, 2018], pred_year=2020)
    dataset = loader.create_training_set()
